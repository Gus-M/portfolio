{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import pandas as pd\n",
    "\n",
    "#Pré-processamento\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "#Automação\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Modelos\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Métricas\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando dataset\n",
    "df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variáveis booleanas\n",
    "bool_vars = ['ind_var30', 'ind_var39_0', 'ind_var43_emit_ult1', 'ind_var43_recib_ult1',\n",
    "             'ind_var5', 'ind_var5_0']\n",
    "\n",
    "#Variáveis categóricas\n",
    "cat_vars = ['num_meses_var12_ult3', 'num_meses_var13_corto_ult3', 'num_meses_var39_vig_ult3',\n",
    "            'num_meses_var5_ult3', 'num_meses_var8_ult3']\n",
    "\n",
    "#Variáveis numéricas\n",
    "num_vars = ['imp_aport_var13_hace3', 'imp_trans_var37_ult1', 'saldo_var30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data sampling\n",
    "# Função para extrair datasets balanceados\n",
    "def getBalancedSample(dataFrame, satisfied_ratio = 1, seed = 0):\n",
    "    #Clientes insatisfeitos\n",
    "    target1_index = dataFrame[dataFrame.TARGET == 1].index\n",
    "    \n",
    "    #Clientes satisfeitos: insatisfeitos * proporção desejada\n",
    "    satisfied_length = len(target1_index) * satisfied_ratio\n",
    "    target0_index = dataFrame[dataFrame.TARGET == 0].sample(satisfied_length, random_state = seed).index\n",
    "    \n",
    "    return(pd.concat([dataFrame.iloc[target1_index],\n",
    "                      dataFrame.iloc[target0_index]], axis = 0))\n",
    "\n",
    "# Datasets para treino\n",
    "seed = 10\n",
    "df_11_ratio = getBalancedSample(df, 1, seed)\n",
    "df_21_ratio = getBalancedSample(df, 2, seed)\n",
    "df_31_ratio = getBalancedSample(df, 3, seed)\n",
    "\n",
    "# Dataset para teste\n",
    "df_test = df.sample(30000, random_state = seed)\n",
    "\n",
    "# Score\n",
    "def model_scoring(model, test_data):\n",
    "    for m in model:\n",
    "        preds = m.predict(test_data)\n",
    "        acc = accuracy_score(test_data.TARGET.ravel(), preds)\n",
    "        rec = recall_score(test_data.TARGET.ravel(), preds)\n",
    "        roc_auc = roc_auc_score(test_data.TARGET.ravel(), preds)\n",
    "        cm = confusion_matrix(test_data.TARGET.ravel(), preds)\n",
    "        print('Accuracy: %.5f\\nRecall: %.5f\\nROC-AUC: %.5f' % (acc, rec, roc_auc))\n",
    "        print(cm)\n",
    "        print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformers\n",
    "prep_ct = ColumnTransformer([['encode_cat', OneHotEncoder(categories='auto', handle_unknown='ignore'), cat_vars],\n",
    "                             ['scale_num', MinMaxScaler(), num_vars],\n",
    "                             ['pass_bool', 'passthrough', bool_vars]],\n",
    "                            remainder='drop',)\n",
    "\n",
    "#Pipeline\n",
    "def fit_pipe_model(model, dataFrame, seed = 0):\n",
    "    #Train/valid split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataFrame.drop('TARGET', axis=1),\n",
    "                                                          dataFrame.TARGET.ravel(),\n",
    "                                                          train_size = 0.7, random_state = seed)\n",
    "    \n",
    "    X = pd.concat([dataFrame[bool_vars],\n",
    "                   dataFrame[cat_vars],\n",
    "                   dataFrame[num_vars]], axis=1)\n",
    "    y = dataFrame.TARGET.ravel()\n",
    "    \n",
    "    #Processando o pipeline\n",
    "    pipe = Pipeline(steps=[('Prep', prep_ct),\n",
    "                           ('Model', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe_preds = pipe.predict(X_valid)\n",
    "    \n",
    "    print('*** Train Validation ***')\n",
    "    acc = accuracy_score(y_valid, pipe_preds) \n",
    "    rec = recall_score(y_valid, pipe_preds) \n",
    "    roc_auc = roc_auc_score(y_valid, pipe_preds)\n",
    "    cm = confusion_matrix(y_valid, pipe_preds)\n",
    "    print('Accuracy: %.5f\\nRecall: %.5f\\nROC-AUC: %.5f' % (acc, rec, roc_auc))\n",
    "    print(cm)\n",
    "    print('-----')\n",
    "    \n",
    "    return(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Train Validation ***\n",
      "Accuracy: 0.67922\n",
      "Recall: 0.70087\n",
      "ROC-AUC: 0.67890\n",
      "[[584 305]\n",
      " [274 642]]\n",
      "-----\n",
      "*** Train Validation ***\n",
      "Accuracy: 0.69904\n",
      "Recall: 0.63123\n",
      "ROC-AUC: 0.68210\n",
      "[[1323  482]\n",
      " [ 333  570]]\n",
      "-----\n",
      "*** Train Validation ***\n",
      "Accuracy: 0.73380\n",
      "Recall: 0.08925\n",
      "ROC-AUC: 0.52335\n",
      "[[2566  114]\n",
      " [ 847   83]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Treino\n",
    "rf_model_11 = fit_pipe_model(RandomForestClassifier(n_estimators=10, random_state=10), df_11_ratio, seed)\n",
    "rf_model_21 = fit_pipe_model(RandomForestClassifier(n_estimators=10, random_state=10), df_21_ratio, seed)\n",
    "rf_model_31 = fit_pipe_model(RandomForestClassifier(n_estimators=10, random_state=10), df_31_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    28837\n",
      "1     1163\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Proporção real do dataset de teste\n",
    "print(df_test.groupby('TARGET')['TARGET'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos 30000 registros selecionados para teste, obtivemos 1163 clientes insatisfeitos e 28837 satisfeitos.\n",
    "\n",
    "Com estes números em mente, vamos avaliar a performance de cada modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65987\n",
      "Recall: 0.79020\n",
      "ROC-AUC: 0.72240\n",
      "[[18877  9960]\n",
      " [  244   919]]\n",
      "-----\n",
      "Accuracy: 0.29933\n",
      "Recall: 0.85469\n",
      "ROC-AUC: 0.56581\n",
      "[[ 7986 20851]\n",
      " [  169   994]]\n",
      "-----\n",
      "Accuracy: 0.92743\n",
      "Recall: 0.21410\n",
      "ROC-AUC: 0.58515\n",
      "[[27574  1263]\n",
      " [  914   249]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Scores\n",
    "model_scoring([rf_model_11, rf_model_21, rf_model_31], df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo 'RF_11' apresentou o melhor resultado, onde conseguiu identificar 919 dos 1163 clientes insatisfeitos com 65.98% de precisão. Vamos utilizar GridSearchCV para otimizar os hiperparâmetros deste modelo enfatizando duas métricas diferentes:\n",
    "\n",
    "* Accuracy (ênfase em classificar corretamente clientes satisfeitos e insatisfeitos)\n",
    "* Recall (ênfase em identificar principalmente os clientes insatisfeitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Train Validation ***\n",
      "Accuracy: 0.69197\n",
      "Recall: 0.69869\n",
      "ROC-AUC: 0.69186\n",
      "[[609 280]\n",
      " [276 640]]\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Train Validation ***\n",
      "Accuracy: 0.68199\n",
      "Recall: 0.70524\n",
      "ROC-AUC: 0.68164\n",
      "[[585 304]\n",
      " [270 646]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#Hiperparâmetros a testar\n",
    "rf_params = {'n_estimators': [10, 30, 100],\n",
    "             'max_depth': [2, 4, 6, None],\n",
    "             'min_samples_split': [2, 10, 20, 30],\n",
    "             'min_samples_leaf': [1, 5, 10, 50]}\n",
    "\n",
    "#Novo modelo\n",
    "rf_cv_acc = GridSearchCV(RandomForestClassifier(random_state=10), param_grid = rf_params,\n",
    "                         scoring = 'accuracy', cv = 5, n_jobs = -1)\n",
    "\n",
    "rf_cv_rec = GridSearchCV(RandomForestClassifier(random_state=10), param_grid = rf_params,\n",
    "                         scoring = 'recall', cv = 5, n_jobs = -1)\n",
    "\n",
    "#Treino do modelo\n",
    "rf_model_11_cv_acc = fit_pipe_model(rf_cv_acc, df_11_ratio, seed)\n",
    "rf_model_11_cv_rec = fit_pipe_model(rf_cv_rec, df_11_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68177\n",
      "Recall: 0.76268\n",
      "ROC-AUC: 0.72059\n",
      "[[19566  9271]\n",
      " [  276   887]]\n",
      "-----\n",
      "Accuracy: 0.66313\n",
      "Recall: 0.81857\n",
      "ROC-AUC: 0.73772\n",
      "[[18942  9895]\n",
      " [  211   952]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#Score\n",
    "model_scoring([rf_model_11_cv_acc, rf_model_11_cv_rec], df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o modelo com ênfase em Accuracy, obtivemos um ganho de 3% nesta métrica ao custo de 3% em recall. Observando a ConfusionMatrix, o modelo melhorou a classificação de clientes satisfeitos, ao passo que piorou a classificação de clientes insatisfeitos\n",
    "\n",
    "Para o modelo com ênfase em Recall, observamos um ganho de 1% em Accuracy e 3% nesta métrica. Conseguimos identificar corretamente mais clientes satisfeitos e insatisfeitos.\n",
    "\n",
    "Vamos submeter os três modelos ao Kaggle e avaliar a performance na competição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando previsões com os dados de teste da competição\n",
    "df_submission = pd.read_csv('../input/test.csv')\n",
    "\n",
    "rf_11_preds = rf_model_11.predict(df_submission)\n",
    "rf_11_cv_acc_preds = rf_model_11_cv_acc.predict(df_submission)\n",
    "rf_11_cv_rec_preds = rf_model_11_cv_rec.predict(df_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparando arquivo para submission\n",
    "rf_11_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "rf_11_cv_acc_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "rf_11_cv_rec_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "\n",
    "rf_11_submission.TARGET = rf_11_preds\n",
    "rf_11_cv_acc_submission.TARGET = rf_11_cv_acc_preds\n",
    "rf_11_cv_rec_submission.TARGET = rf_11_cv_rec_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_11_submission.to_csv('../output/rf_11_submission.csv', index=False)\n",
    "rf_11_cv_acc_submission.to_csv('../output/rf_11_cv_acc_submission.csv', index=False)\n",
    "rf_11_cv_rec_submission.to_csv('../output/rf_11_cv_rec_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle_submission](../presentation/kaggle_submission.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A métrica utilizada na competição é a ROC-AUC. Os resultados obtidos estão ligeiramente inferiores aos observados durante a criação do modelo neste trabalho.\n",
    "\n",
    "Os três modelos apresentaram performances similares, sendo que o 'RF_11_cv_acc' apresentou o melhor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rf_model_11_cv_acc.named_steps['Model'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=20,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=10, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hiperparâmetros selecionados para o modelo\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentre os parâmetros fornecidos, a melhor combinação encontrada foi:\n",
    "\n",
    "* n_estimators=100\n",
    "* max_depth=None\n",
    "* min_samples_leaf=1\n",
    "* min_samples_split=20\n",
    "\n",
    "As árvores de decisão realizaram splits a cada 20 amostras. Entretanto, cada amostra resultou na criação de um leaf (decisão), o que sugere baixa capacidade de generalização deste modelo visto que cada amostra ao final de um split resultará em uma decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.011071\n",
       "1     0.001972\n",
       "2     0.003319\n",
       "3     0.006224\n",
       "4     0.010221\n",
       "5     0.001313\n",
       "6     0.003224\n",
       "7     0.002525\n",
       "8     0.008605\n",
       "9     0.026395\n",
       "10    0.014645\n",
       "11    0.003176\n",
       "12    0.079455\n",
       "13    0.011542\n",
       "14    0.015184\n",
       "15    0.098420\n",
       "16    0.014511\n",
       "17    0.002993\n",
       "18    0.004351\n",
       "19    0.000880\n",
       "20    0.008614\n",
       "21    0.045503\n",
       "22    0.429923\n",
       "23    0.066695\n",
       "24    0.014161\n",
       "25    0.019397\n",
       "26    0.012211\n",
       "27    0.067256\n",
       "28    0.016215\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observando o grau de importância das features selecionadas\n",
    "pd.Series(best_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os indices acima representam:\n",
    "\n",
    "* 0 a 19: Variáveis categóricas processadas com OneHotEncoding\n",
    "* 20 a 22: Variáveis numéricas selecionadas via PCA\n",
    "* 23 a 28: Variáveis booleanas selecionadas\n",
    "\n",
    "A maioria das features utilizadas neste modelo possui baixa importância. sendo a variável 22 (saldo_var30) a mais significativa.\n",
    "\n",
    "Essa análise sugere que podemos melhorar a performance deste modelo selecionando e/ou concebendo novas features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
